---
title: 对“属性不确定的对象”如何进行数据建模的思考(Part 1)
date: 2018-01-10 16:52:33
tags:
- Mongodb
---

# 背景

部门里有同学负责一个任务分派系统（以下简称**T系统**），其用户主要是公司里的客服人员。T系统的作用主要是为这些客服人员提供可视化的任务搜索、任务分派、任务追踪功能，简单来说用户打开T系统后就能看到自己手头上的任务或者新生成还没被人拿走的任务，然后可以对它们进行操作，并且在任务状态改变时可以在UI上看到他们的变化。

这里要着重点出的是：**T系统里有很多不同类型的任务，而不同类型的任务的属性是不一样的（会有少部分公共属性是一样的，其余大部分任务私有属性是不同的），并且用户还可以新增自定义任务和它们的属性。T系统还对用户提供了搜索功能能够基于任务属性做过滤。**数据模型例子：

```json
// 任务类型1
{
    // 公共属性
    type: "A",
    createTime: "20180101",
    // 私有属性
    p1: "v1",
    p2: "v2",
}

// 任务类型2
{
    // 公共属性
    type: "B",
    createTime: "20180102",
    // 私有属性
    p3: "v3",
    p4: "v4",
}
```
由于T系统是从别人手里接手过来的，拿到手时系统的基本框架、数据模型、数据流等都已经被确定了。基于公司高层对Oracle数据库的虔诚信仰，T系统底层的数据存储自然选用的就是Oracle RDBMS了（包括公司内部其它系统全都是Oracle RDBMS）。

首先，RDBMS能提供一个非常重要的性质：ACID，简单来说就是保证一个操作多个表的多行数据的事务是原子性的，也就是中间失败了前面的操作会回滚，并且提供了事务间的隔离性，防止读到脏数据。这个性质对维持数据的一致性非常重要，如果没有这个性质，那么应用程序就要自己去处理失败回滚的问题，这样会导致程序逻辑非常复杂。

回到T系统，它是怎么把任务数据存储到RDBMS里的呢？也就是它的数据建模是怎么做的呢？按照当前的设计，任务数据存放在2张表里：任务基本信息表（TaskBase表）、任务私有属性表（TaskDetail表）。
1. TaskBase表：存放任务PK、公共信息。每个任务在这张表里只有一条记录。
2. TaskDetail表：存放任务私有属性，每个任务的一个属性作为一个K-V对（也就是这个表有2列，一个列存放属性名，另一个列存放属性值）存放到这个表中，并通过FK关联到TaskBase表，指明属性是属于哪个任务的。一般一个任务都会有20+个属性。

具体例子可以参考下图：

![](https://raw.githubusercontent.com/yellowb/yellowb.github.io/hexo/source/uploads/20180110/rdbms_ER.png)

为什么这样设计呢？个人估计是由于任务的私有属性种类在业务上是无法固化的，也就是可能随时变化的，每种任务的属性也不一样。对于这种“属性不确定的对象”，用RDBMS是无法很好的匹配的，主要有如下一些问题：
1. 因为RDBMS的结构是一张列基本确定的二维表，虽然可以对列做增删，但是数据量大时很麻烦。
2. 如果我们穷举所有任务的所有属性得到一个属性集，然后把属性集的每一个属性作为一个列，则我们会得到一个列数非常多的表，而且这张表可能非常稀疏（想象一下，如果对于一些属性，某一类型的任务是没有的，那么这些任务数据的相应列都是空的，进而造成这张表很多空值，浪费空间）。
3. 业务上这些任务的属性是可以被用户自定义的，如果用户每增加一个属性，我们就增加一个列，那么这个工作量是无法想象的。

所以当前T系统采用了一种折中的方案：把任务的私有属性放到另一张表中，用K-V的形式存储。然而这种设计也带来一些问题：
1. 单表数据量极大：由于每个任务可能有几十个属性，所以TaskDetail表会几十倍于TaskBase表，当前已经到达了好几亿的量级（这还是只保留最近几个月的数据的情况下），而且没有做任何的分表。按照以前看到阿里内部指南所说，不建议单表容量超过5M，当然我们用的是牛逼的Oracle数据库和高性能一体机，可能这个上限还能更高些，不过无论如何把上亿的数据塞到一个表中也不是什么好的实践。
2. 查询速度慢：查询有等值、范围、模糊几种，并且会在多个属性上做组合。虽然已经为TaskDetail表的Field和Value建立联合索引，但由于这个表数据量太大，即使走索引也要读取大量块。而且因为每个用户只会读他关注的那部分任务，所以看起来并不会有太热的数据，可能数据库缓存也不太好使。更别提会在一些Value上用Like来检索了...
3. 由于RDBMS每个列的数据类型都是预先定义的，为了兼顾到不同属性，这里Value列用的是varchar2，也就是说不管存储的是数值还是日期（实际上还是数值），都必须变成字符串，众所周知字符串消耗的空间要比数值大得多。（想象下"100000000" vs 100000000）

**总结一下：**
1. T系统把一些属性动态变化的对象变成K-V的形式存储到RDBMS。
2. 由于没有为检索做更多的优化，完全用DB来扛，导致性能堪忧。

# 一些思考
如果不对用户需求做任何改变，仅仅从数据存储和性能的层面来看，当前T系统的数据建模是否合适？

以前曾经参加过一次MongoDB的会议，会上有网易游戏的运维哥哥说到，以前他们用的是MySQL存储游戏角色数据，而游戏策划经常对角色属性进行更改（比如加技能、加装备等），每次变更都要对MySQL表加列，使得他们非常痛苦。后来他们迁移到MongoDB，由于MongoDB是Schemaless的，所以可以随时加新的属性，并且每条记录的属性都可以不一样，这个迁移让他们运维的难度大大降低，引用他们的原话就是“舒服多了”。

那么如果我们像网易游戏哥哥一样采用Schemaless的数据库来建模，是不是会有一些不同？下面先来对比一下不同类型数据库的特点。

## 不同类型数据库的对比
![](https://raw.githubusercontent.com/yellowb/yellowb.github.io/hexo/source/uploads/20180110/db-roadmap.jpg)

### 1.RDBMS
从上世纪70年代E.F.Codd的论文《A Relational Modelof Data for Large Shared Data Banks》和SQL语言被提出开始，到80年代各种商用数据库比如Oracle、MS SQL等的推出，RDBMS在银行、电信等行业得到广泛应用。

这种数据库的特点就是完全实现了上面论文的关系模型、支持SQL，并且提供ACID特性。对于应用来说，不需要关注事务失败回滚等细节，非常易于使用。然而这个时代的数据库基本是单节点的，要提升性能基本是靠Scale-Up的方式，也就是买更贵的硬件。

2000年之后，由于互联网的兴起，大型互联网公司需要存储的数据的量非常大，这时候如果还是靠买更贵的硬件来升级，成本上行不通，另外即使成本不是问题，最贵的硬件的性能也不能满足这些公司的需求了。这时候一些互联网公司纷纷投向MySQL，并通过中间件的方式，实现了把大量数据拆分到多个MySQL实例中，满足了对海量数据的存储要求。不过对于单个数据库节点来说，其自身仍然是一个单机版的数据库，只不过是靠中间件实现了路由把多个单节点数据库组合起来了。

如果套用分布式领域的[CAP理论](http://www.hollischuang.com/archives/666 "CAP理论")来分析，RDBMS支持的就是C（一致性）和A（可用性）。

### 2.NoSQL
互联网兴起后，特别是社交等应用的火爆，对存储系统的容量和吞吐量提出了更高的要求，这时候传统RDBMS已经不太适应。结合这类应用的特点（比如不需要强一致性、丢失一些数据是可以容忍的），NoSQL被提出来了。

NoSQL是一个模糊的概念，我的理解是为了满足一些特殊需求，在原先RDBMS支持的特性上做减法，去掉一些不需要的特性，从而产生的为某种目的特殊进化的数据库。比如为了拥有高水平扩展性，有些NoSQL数据库把事务隔离、Join、FK等特性舍弃；又比如为了追求高吞吐量，只支持K-V类型的数据结构并且只用内存存储。

NoSQL在互联网公司里被大量地使用，但是核心的（比如交易、订单等牵涉到金钱的，不允许出现数据不一致）业务也还是RDBMS居多，因为那些被NoSQL抛弃的原先RDBMS拥有的特性，实际上是转嫁到了应用层面去handle，而这个是非常复杂的。





















